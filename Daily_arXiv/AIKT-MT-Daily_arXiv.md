# Daily arXiv: Machine Translation - Mar., 2020

# Index

- [2020-04-01](#2020-04-01)
  - [1. The European Language Technology Landscape in 2020: Language-Centric and Human-Centric AI for Cross-Cultural Communication in Multilingual Europe](#2020-04-01-1)
  - [2. MULTEXT-East](#2020-04-01-2)
  - [3. Understanding Cross-Lingual Syntactic Transfer in Multilingual Recurrent Neural Networks](#2020-04-01-3)
  - [4. On the Integration of LinguisticFeatures into Statistical and Neural Machine Translation](#2020-04-01-4)
  - [5. Evaluating Amharic Machine Translation](#2020-04-01-5)
  - [6. Low Resource Neural Machine Translation: A Benchmark for Five African Languages](#2020-04-01-6)
- [2020-03](https://github.com/SFFAI-AIKT/AIKT-Natural_Language_Processing/blob/master/Daily_arXiv/AIKT-MT-Daily_arXiv-2020-03.md)
- [2020-02](https://github.com/SFFAI-AIKT/AIKT-Natural_Language_Processing/blob/master/Daily_arXiv/AIKT-MT-Daily_arXiv-2020-02.md)
- [2020-01](https://github.com/SFFAI-AIKT/AIKT-Natural_Language_Processing/blob/master/Daily_arXiv/AIKT-MT-Daily_arXiv-2020-01.md)
- [2019-12](https://github.com/SFFAI-AIKT/AIKT-Natural_Language_Processing/blob/master/Daily_arXiv/AIKT-MT-Daily_arXiv-2019-12.md)
- [2019-11](https://github.com/SFFAI-AIKT/AIKT-Natural_Language_Processing/blob/master/Daily_arXiv/AIKT-MT-Daily_arXiv-2019-11.md)
- [2019-10](https://github.com/SFFAI-AIKT/AIKT-Natural_Language_Processing/blob/master/Daily_arXiv/AIKT-MT-Daily_arXiv-2019-10.md)
- [2019-09](https://github.com/SFFAI-AIKT/AIKT-Natural_Language_Processing/blob/master/Daily_arXiv/AIKT-MT-Daily_arXiv-2019-09.md)
- [2019-08](https://github.com/SFFAI-AIKT/AIKT-Natural_Language_Processing/blob/master/Daily_arXiv/AIKT-MT-Daily_arXiv-2019-08.md)
- [2019-07](https://github.com/SFFAI-AIKT/AIKT-Natural_Language_Processing/blob/master/Daily_arXiv/AIKT-MT-Daily_arXiv-2019-07.md)
- [2019-06](https://github.com/SFFAI-AIKT/AIKT-Natural_Language_Processing/blob/master/Daily_arXiv/AIKT-MT-Daily_arXiv-2019-06.md)
- [2019-05](https://github.com/SFFAI-AIKT/AIKT-Natural_Language_Processing/blob/master/Daily_arXiv/AIKT-MT-Daily_arXiv-2019-05.md)
- [2019-04](https://github.com/SFFAI-AIKT/AIKT-Natural_Language_Processing/blob/master/Daily_arXiv/AIKT-MT-Daily_arXiv-2019-04.md)
- [2019-03](https://github.com/SFFAI-AIKT/AIKT-Natural_Language_Processing/blob/master/Daily_arXiv/AIKT-MT-Daily_arXiv-2019-03.md)



# 2020-04-01

[Return to Index](#Index)



<h2 id="2020-04-01-1">1. The European Language Technology Landscape in 2020: Language-Centric and Human-Centric AI for Cross-Cultural Communication in Multilingual Europe</h2>

Title: [The European Language Technology Landscape in 2020: Language-Centric and Human-Centric AI for Cross-Cultural Communication in Multilingual Europe](https://arxiv.org/abs/2003.13833)

Authors: [Georg Rehm](https://arxiv.org/search/cs?searchtype=author&query=Rehm%2C+G), [Katrin Marheinecke](https://arxiv.org/search/cs?searchtype=author&query=Marheinecke%2C+K), [Stefanie Hegele](https://arxiv.org/search/cs?searchtype=author&query=Hegele%2C+S), [Stelios Piperidis](https://arxiv.org/search/cs?searchtype=author&query=Piperidis%2C+S), [Kalina Bontcheva](https://arxiv.org/search/cs?searchtype=author&query=Bontcheva%2C+K), [Jan Hajič](https://arxiv.org/search/cs?searchtype=author&query=Hajič%2C+J), [Khalid Choukri](https://arxiv.org/search/cs?searchtype=author&query=Choukri%2C+K), [Andrejs Vasiļjevs](https://arxiv.org/search/cs?searchtype=author&query=Vasiļjevs%2C+A), [Gerhard Backfried](https://arxiv.org/search/cs?searchtype=author&query=Backfried%2C+G), [Christoph Prinz](https://arxiv.org/search/cs?searchtype=author&query=Prinz%2C+C), [José Manuel Gómez Pérez](https://arxiv.org/search/cs?searchtype=author&query=Pérez%2C+J+M+G), [Luc Meertens](https://arxiv.org/search/cs?searchtype=author&query=Meertens%2C+L), [Paul Lukowicz](https://arxiv.org/search/cs?searchtype=author&query=Lukowicz%2C+P), [Josef van Genabith](https://arxiv.org/search/cs?searchtype=author&query=van+Genabith%2C+J), [Andrea Lösch](https://arxiv.org/search/cs?searchtype=author&query=Lösch%2C+A), [Philipp Slusallek](https://arxiv.org/search/cs?searchtype=author&query=Slusallek%2C+P), [Morten Irgens](https://arxiv.org/search/cs?searchtype=author&query=Irgens%2C+M), [Patrick Gatellier](https://arxiv.org/search/cs?searchtype=author&query=Gatellier%2C+P), [Joachim Köhler](https://arxiv.org/search/cs?searchtype=author&query=Köhler%2C+J), [Laure Le Bars](https://arxiv.org/search/cs?searchtype=author&query=Bars%2C+L+L), [Dimitra Anastasiou](https://arxiv.org/search/cs?searchtype=author&query=Anastasiou%2C+D), [Albina Auksoriūtė](https://arxiv.org/search/cs?searchtype=author&query=Auksoriūtė%2C+A), [Núria Bel](https://arxiv.org/search/cs?searchtype=author&query=Bel%2C+N), [António Branco](https://arxiv.org/search/cs?searchtype=author&query=Branco%2C+A), [Gerhard Budin](https://arxiv.org/search/cs?searchtype=author&query=Budin%2C+G), [Walter Daelemans](https://arxiv.org/search/cs?searchtype=author&query=Daelemans%2C+W), [Koenraad De Smedt](https://arxiv.org/search/cs?searchtype=author&query=De+Smedt%2C+K), [Radovan Garabík](https://arxiv.org/search/cs?searchtype=author&query=Garabík%2C+R), [Maria Gavriilidou](https://arxiv.org/search/cs?searchtype=author&query=Gavriilidou%2C+M), [Dagmar Gromann](https://arxiv.org/search/cs?searchtype=author&query=Gromann%2C+D), [Svetla Koeva](https://arxiv.org/search/cs?searchtype=author&query=Koeva%2C+S), [Simon Krek](https://arxiv.org/search/cs?searchtype=author&query=Krek%2C+S), [Cvetana Krstev](https://arxiv.org/search/cs?searchtype=author&query=Krstev%2C+C), [Krister Lindén](https://arxiv.org/search/cs?searchtype=author&query=Lindén%2C+K), [Bernardo Magnini](https://arxiv.org/search/cs?searchtype=author&query=Magnini%2C+B), [Jan Odijk](https://arxiv.org/search/cs?searchtype=author&query=Odijk%2C+J), [Maciej Ogrodniczuk](https://arxiv.org/search/cs?searchtype=author&query=Ogrodniczuk%2C+M), [Eiríkur Rögnvaldsson](https://arxiv.org/search/cs?searchtype=author&query=Rögnvaldsson%2C+E), [Mike Rosner](https://arxiv.org/search/cs?searchtype=author&query=Rosner%2C+M), [Bolette Sandford Pedersen](https://arxiv.org/search/cs?searchtype=author&query=Pedersen%2C+B+S), [Inguna Skadiņa](https://arxiv.org/search/cs?searchtype=author&query=Skadiņa%2C+I), [Marko Tadić](https://arxiv.org/search/cs?searchtype=author&query=Tadić%2C+M), [Dan Tufiş](https://arxiv.org/search/cs?searchtype=author&query=Tufiş%2C+D), [Tamás Váradi](https://arxiv.org/search/cs?searchtype=author&query=Váradi%2C+T), [Kadri Vider](https://arxiv.org/search/cs?searchtype=author&query=Vider%2C+K), [Andy Way](https://arxiv.org/search/cs?searchtype=author&query=Way%2C+A), [François Yvon](https://arxiv.org/search/cs?searchtype=author&query=Yvon%2C+F)

*(Submitted on 30 Mar 2020)*

> Multilingualism is a cultural cornerstone of Europe and firmly anchored in the European treaties including full language equality. However, language barriers impacting business, cross-lingual and cross-cultural communication are still omnipresent. Language Technologies (LTs) are a powerful means to break down these barriers. While the last decade has seen various initiatives that created a multitude of approaches and technologies tailored to Europe's specific needs, there is still an immense level of fragmentation. At the same time, AI has become an increasingly important concept in the European Information and Communication Technology area. For a few years now, AI, including many opportunities, synergies but also misconceptions, has been overshadowing every other topic. We present an overview of the European LT landscape, describing funding programmes, activities, actions and challenges in the different countries with regard to LT, including the current state of play in industry and the LT market. We present a brief overview of the main LT-related activities on the EU level in the last ten years and develop strategic guidance with regard to four key dimensions.

| Comments: | Proceedings of the 12th Language Resources and Evaluation Conference (LREC 2020). To appear |
| --------- | ------------------------------------------------------------ |
| Subjects: | **Computation and Language (cs.CL)**; Artificial Intelligence (cs.AI) |
| Cite as:  | [arXiv:2003.13833](https://arxiv.org/abs/2003.13833) [cs.CL] |
|           | (or [arXiv:2003.13833v1](https://arxiv.org/abs/2003.13833v1) [cs.CL] for this version) |





<h2 id="2020-04-01-2">2. MULTEXT-East</h2>

Title: [MULTEXT-East](https://arxiv.org/abs/2003.14026)

Authors: [Tomaž Erjavec](https://arxiv.org/search/cs?searchtype=author&query=Erjavec%2C+T)

*(Submitted on 31 Mar 2020)*

> MULTEXT-East language resources, a multilingual dataset for language engineering research, focused on the morphosyntactic level of linguistic description. The MULTEXT-East dataset includes the EAGLES-based morphosyntactic specifications, morphosyntactic lexicons, and an annotated multilingual corpora. The parallel corpus, the novel "1984" by George Orwell, is sentence aligned and contains hand-validated morphosyntactic descriptions and lemmas. The resources are uniformly encoded in XML, using the Text Encoding Initiative Guidelines, TEI P5, and cover 16 languages: Bulgarian, Croatian, Czech, English, Estonian, Hungarian, Macedonian, Persian, Polish, Resian, Romanian, Russian, Serbian, Slovak, Slovene, and Ukrainian. This dataset is extensively documented, and freely available for research purposes. This case study gives a history of the development of the MULTEXT-East resources, presents their encoding and components, discusses related work and gives some conclusions.

| Subjects:          | **Computation and Language (cs.CL)**                         |
| ------------------ | ------------------------------------------------------------ |
| ACM classes:       | I.2.7                                                        |
| Journal reference: | Published in: Nancy Ide, James Pustejovsky, eds. 2007. Handbook of linguistic annotation. pp. 441-462. Springer |
| DOI:               | [10.1007/978-94-024-0881-2_17](https://arxiv.org/ct?url=https%3A%2F%2Fdx.doi.org%2F10.1007%2F978-94-024-0881-2_17&v=6fb4b8b1) |
| Cite as:           | [arXiv:2003.14026](https://arxiv.org/abs/2003.14026) [cs.CL] |
|                    | (or [arXiv:2003.14026v1](https://arxiv.org/abs/2003.14026v1) [cs.CL] for this version) |





<h2 id="2020-04-01-3">3. Understanding Cross-Lingual Syntactic Transfer in Multilingual Recurrent Neural Networks</h2>

Title: [Understanding Cross-Lingual Syntactic Transfer in Multilingual Recurrent Neural Networks](https://arxiv.org/abs/2003.14056)

Authors: [Prajit Dhar](https://arxiv.org/search/cs?searchtype=author&query=Dhar%2C+P), [Arianna Bisazza](https://arxiv.org/search/cs?searchtype=author&query=Bisazza%2C+A)

*(Submitted on 31 Mar 2020)*

> It is now established that modern neural language models can be successfully trained on multiple languages simultaneously without changes to the underlying architecture, providing an easy way to adapt a variety of NLP models to low-resource languages. But what kind of knowledge is really shared among languages within these models? Does multilingual training mostly lead to an alignment of the lexical representation spaces or does it also enable the sharing of purely grammatical knowledge? In this paper we dissect different forms of cross-lingual transfer and look for its most determining factors, using a variety of models and probing tasks. We find that exposing our language models to a related language does not always increase grammatical knowledge in the target language, and that optimal conditions for lexical-semantic transfer may not be optimal for syntactic transfer.

| Comments: | 9 pages single column with 6 figures                         |
| --------- | ------------------------------------------------------------ |
| Subjects: | **Computation and Language (cs.CL)**; Machine Learning (cs.LG) |
| Cite as:  | [arXiv:2003.14056](https://arxiv.org/abs/2003.14056) [cs.CL] |
|           | (or [arXiv:2003.14056v1](https://arxiv.org/abs/2003.14056v1) [cs.CL] for this version) |





<h2 id="2020-04-01-4">4. On the Integration of LinguisticFeatures into Statistical and Neural Machine Translation</h2>

Title: [On the Integration of LinguisticFeatures into Statistical and Neural Machine Translation](https://arxiv.org/abs/2003.14324)

Authors: [Eva Vanmassenhove](https://arxiv.org/search/cs?searchtype=author&query=Vanmassenhove%2C+E)

*(Submitted on 31 Mar 2020)*

> New machine translations (MT) technologies are emerging rapidly and with them, bold claims of achieving human parity such as: (i) the results produced approach "accuracy achieved by average bilingual human translators" (Wu et al., 2017b) or (ii) the "translation quality is at human parity when compared to professional human translators" (Hassan et al., 2018) have seen the light of day (Laubli et al., 2018). Aside from the fact that many of these papers craft their own definition of human parity, these sensational claims are often not supported by a complete analysis of all aspects involved in translation. Establishing the discrepancies between the strengths of statistical approaches to MT and the way humans translate has been the starting point of our research. By looking at MT output and linguistic theory, we were able to identify some remaining issues. The problems range from simple number and gender agreement errors to more complex phenomena such as the correct translation of aspectual values and tenses. Our experiments confirm, along with other studies (Bentivogli et al., 2016), that neural MT has surpassed statistical MT in many aspects. However, some problems remain and others have emerged. We cover a series of problems related to the integration of specific linguistic features into statistical and neural MT, aiming to analyse and provide a solution to some of them. Our work focuses on addressing three main research questions that revolve around the complex relationship between linguistics and MT in general. We identify linguistic information that is lacking in order for automatic translation systems to produce more accurate translations and integrate additional features into the existing pipelines. We identify overgeneralization or 'algorithmic bias' as a potential drawback of neural MT and link it to many of the remaining linguistic issues.

| Subjects: | **Computation and Language (cs.CL)**; Artificial Intelligence (cs.AI) |
| --------- | ------------------------------------------------------------ |
| Cite as:  | [arXiv:2003.14324](https://arxiv.org/abs/2003.14324) [cs.CL] |
|           | (or [arXiv:2003.14324v1](https://arxiv.org/abs/2003.14324v1) [cs.CL] for this version) |





<h2 id="2020-04-01-5">5. Evaluating Amharic Machine Translation</h2>

Title: [Evaluating Amharic Machine Translation](https://arxiv.org/abs/2003.14386)

Authors: [Asmelash Teka Hadgu](https://arxiv.org/search/cs?searchtype=author&query=Hadgu%2C+A+T), [Adam Beaudoin](https://arxiv.org/search/cs?searchtype=author&query=Beaudoin%2C+A), [Abel Aregawi](https://arxiv.org/search/cs?searchtype=author&query=Aregawi%2C+A)

*(Submitted on 31 Mar 2020)*

> Machine translation (MT) systems are now able to provide very accurate results for high resource language pairs. However, for many low resource languages, MT is still under active research. In this paper, we develop and share a dataset to automatically evaluate the quality of MT systems for Amharic. We compare two commercially available MT systems that support translation of Amharic to and from English to assess the current state of MT for Amharic. The BLEU score results show that the results for Amharic translation are promising but still low. We hope that this dataset will be useful to the research community both in academia and industry as a benchmark to evaluate Amharic MT systems.

| Comments: | 4 pages                                                      |
| --------- | ------------------------------------------------------------ |
| Subjects: | **Computation and Language (cs.CL)**                         |
| Cite as:  | [arXiv:2003.14386](https://arxiv.org/abs/2003.14386) [cs.CL] |
|           | (or [arXiv:2003.14386v1](https://arxiv.org/abs/2003.14386v1) [cs.CL] for this version) |







<h2 id="2020-04-01-6">6. Low Resource Neural Machine Translation: A Benchmark for Five African Languages</h2>

Title: [Low Resource Neural Machine Translation: A Benchmark for Five African Languages](https://arxiv.org/abs/2003.14402)

Authors: [Surafel M. Lakew](https://arxiv.org/search/cs?searchtype=author&query=Lakew%2C+S+M), [Matteo Negri](https://arxiv.org/search/cs?searchtype=author&query=Negri%2C+M), [Marco Turchi](https://arxiv.org/search/cs?searchtype=author&query=Turchi%2C+M)

*(Submitted on 31 Mar 2020)*

> Recent advents in Neural Machine Translation (NMT) have shown improvements in low-resource language (LRL) translation tasks. In this work, we benchmark NMT between English and five African LRL pairs (Swahili, Amharic, Tigrigna, Oromo, Somali [SATOS]). We collected the available resources on the SATOS languages to evaluate the current state of NMT for LRLs. Our evaluation, comparing a baseline single language pair NMT model against semi-supervised learning, transfer learning, and multilingual modeling, shows significant performance improvements both in the En-LRL and LRL-En directions. In terms of averaged BLEU score, the multilingual approach shows the largest gains, up to +5 points, in six out of ten translation directions. To demonstrate the generalization capability of each model, we also report results on multi-domain test sets. We release the standardized experimental data and the test sets for future works addressing the challenges of NMT in under-resourced settings, in particular for the SATOS languages.

| Comments: | Accepted for AfricaNLP workshop at ICLR 2020                 |
| --------- | ------------------------------------------------------------ |
| Subjects: | **Computation and Language (cs.CL)**                         |
| Cite as:  | [arXiv:2003.14402](https://arxiv.org/abs/2003.14402) [cs.CL] |
|           | (or [arXiv:2003.14402v1](https://arxiv.org/abs/2003.14402v1) [cs.CL] for this version) |