# Daily arXiv: Machine Translation - Apr., 2019

### Index

- [2019-04-02](#2019-04-02)
  - [1. Machine translation considering context information using Encoder-Decoder model](#2019-04-01-1)
  - [2. Multimodal Machine Translation with Embedding Prediction](#2019-04-02-2)
  - [3. Lost in Interpretation: Predicting Untranslated Terminology in Simultaneous Interpretation](#2019-04-02-3)

* [2019-03](https://github.com/SFFAI-AIKT/AIKT-Natural_Language_Processing/blob/master/Daily_arXiv/AIKT-MT-Daily_arXiv-2019-03.md)
* [2019-02](https://github.com/SFFAI-AIKT/AIKT-Natural_Language_Processing/blob/master/Daily_arXiv/AIKT-MT-Daily_arXiv-2019-02.md)



# 2019-04-02

[Return to Index](#Index)

<h2 id="2019-04-02-1">1. Machine translation considering context information using Encoder-Decoder model</h2> 

Title: [Machine translation considering context information using Encoder-Decoder model](<https://arxiv.org/abs/1904.00160>)

Authors:[Tetsuto Takano](https://arxiv.org/search/cs?searchtype=author&query=Takano%2C+T), [Satoshi Yamane](https://arxiv.org/search/cs?searchtype=author&query=Yamane%2C+S)

(Submitted on 30 Mar 2019)

> In the task of machine translation, context information is one of the important factor. But considering the context information model dose not proposed. The paper propose a new model which can integrate context information and make translation. In this paper, we create a new model based Encoder Decoder model. When translating current sentence, the model integrates output from preceding encoder with current encoder. The model can consider context information and the result score is higher than existing model.

| Subjects: | **Computation and Language (cs.CL)**; Machine Learning (cs.LG) |
| --------- | ------------------------------------------------------------ |
| Cite as:  | [arXiv:1904.00160](https://arxiv.org/abs/1904.00160) [cs.CL] |
|           | (or **arXiv:1904.00160v1 [cs.CL]** for this version)         |



<h2 id="2019-04-02-2">2. Multimodal Machine Translation with Embedding Prediction</h2> 

Title: [Multimodal Machine Translation with Embedding Prediction](<https://arxiv.org/abs/1904.00639>)

Authors: [Tosho Hirasawa](https://arxiv.org/search/cs?searchtype=author&query=Hirasawa%2C+T), [Hayahide Yamagishi](https://arxiv.org/search/cs?searchtype=author&query=Yamagishi%2C+H), [Yukio Matsumura](https://arxiv.org/search/cs?searchtype=author&query=Matsumura%2C+Y), [Mamoru Komachi](https://arxiv.org/search/cs?searchtype=author&query=Komachi%2C+M)

(Submitted on 1 Apr 2019)

> Multimodal machine translation is an attractive application of neural machine translation (NMT). It helps computers to deeply understand visual objects and their relations with natural languages. However, multimodal NMT systems suffer from a shortage of available training data, resulting in poor performance for translating rare words. In NMT, pretrained word embeddings have been shown to improve NMT of low-resource domains, and a search-based approach is proposed to address the rare word problem. In this study, we effectively combine these two approaches in the context of multimodal NMT and explore how we can take full advantage of pretrained word embeddings to better translate rare words. We report overall performance improvements of 1.24 METEOR and 2.49 BLEU and achieve an improvement of 7.67 F-score for rare word translation.

| Comments: | 6 pages; NAACL 2019 Student Research Workshop                |
| --------- | ------------------------------------------------------------ |
| Subjects: | **Computation and Language (cs.CL)**                         |
| Cite as:  | [arXiv:1904.00639](https://arxiv.org/abs/1904.00639) [cs.CL] |
|           | (or **arXiv:1904.00639v1 [cs.CL]** for this version)         |



<h2 id="2019-04-02-3">3. Lost in Interpretation: Predicting Untranslated Terminology in Simultaneous Interpretation</h2> 

Title: [Lost in Interpretation: Predicting Untranslated Terminology in Simultaneous Interpretation](<https://arxiv.org/abs/1904.00930>)

Authors: [Nikolai Vogler](https://arxiv.org/search/cs?searchtype=author&query=Vogler%2C+N), [Craig Stewart](https://arxiv.org/search/cs?searchtype=author&query=Stewart%2C+C), [Graham Neubig](https://arxiv.org/search/cs?searchtype=author&query=Neubig%2C+G)

(Submitted on 1 Apr 2019)

> Simultaneous interpretation, the translation of speech from one language to another in real-time, is an inherently difficult and strenuous task. One of the greatest challenges faced by interpreters is the accurate translation of difficult terminology like proper names, numbers, or other entities. Intelligent computer-assisted interpreting (CAI) tools that could analyze the spoken word and detect terms likely to be untranslated by an interpreter could reduce translation error and improve interpreter performance. In this paper, we propose a task of predicting which terminology simultaneous interpreters will leave untranslated, and examine methods that perform this task using supervised sequence taggers. We describe a number of task-specific features explicitly designed to indicate when an interpreter may struggle with translating a word. Experimental results on a newly-annotated version of the NAIST Simultaneous Translation Corpus (Shimizu et al., 2014) indicate the promise of our proposed method.

| Comments: | NAACL 2019                                                   |
| --------- | ------------------------------------------------------------ |
| Subjects: | **Computation and Language (cs.CL)**                         |
| Cite as:  | [arXiv:1904.00930](https://arxiv.org/abs/1904.00930) [cs.CL] |
|           | (or **arXiv:1904.00930v1 [cs.CL]** for this version)         |